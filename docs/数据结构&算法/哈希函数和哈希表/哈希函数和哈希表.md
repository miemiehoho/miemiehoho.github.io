# 哈希函数和哈希表

# 学习笔记

### 哈希函数

#### 特征

1. 输入域相对来说无穷大，输出域相对有限
2. 

   - 哈希函数是一种确定规则的函数 - 无随机（相同的输入一定能够得到相同的输出）
   - 即便是不同的输入也可能导致相同的输出：哈希碰撞
3. 哈希函数的输出是**离散**的，**均匀分布**（和输入没有关系）
3. 哈希函数的输出取模（%）后仍然是均匀分布的

特征 3 决定了一个哈希函数的好坏

#### 哈希函数的离散性（均匀性）

在一片区域内点很多个点，随便圈出来一个区域，每个区域的点的数量是差不多的

#### 作用

- 离散

### 哈希表

#### 原理

**存储：**

1. 假设哈希表存储key的数组的长度是 17（长度一般为质数）
2. 每存一个值 key,利用哈希函数计算出key的哈希值，然后%17，计算出key的存储位置
3. 将key存储到对应的位置（以链表的方式存储；根据哈希函数的离散型，数组中每个链表的长度是均匀增长的）

**查找：**

1. ,利用哈希函数计算出key的哈希值，然后%17，计算出key的存储位置
2. 去哈希表对应位置的链表中查找是否存在value

#### 扩容

**扩容条件：**在进行add、query、update操作时，如果发现某一链表的长度超过了一定的阈值，就需要进行扩容操作（由于哈希函数的离散型，如果某一链表的长度达到了一定的阈值，就可以认为哈希表的其他链表长度也达到了阈值）

**扩容方式：**

1. 哈希表长度变为原来的两倍
2. 把哈希表中所有key重新计算一次哈希函数，然后%现在的哈希表长度，计算出当前key应该存储的新位置，以此完成哈希表的扩容操作

**扩容代价分析：**

扩容次数：$log^N$级别,（$Clog^N$，常数项C与链表的长度有关，常数项可以忽略）

单次次扩容的代价：O(N)

当数据量从 0 增长到 N 的时候扩容的总代价：$O(N*log^N)$

每加入一条数据的扩容平均代价：$log^N$，而且常数项 C 可以做到非常小

**哈希表长度取质数原因：**

在数学上分析可知：哈希表长度取质数会使哈希表的分布更加均匀

（实例：哈希函数需要把原始数据均匀地分布到哈希数组里，比如大部分是偶数，这时候如果哈希数组容量是偶数，容易使原始数据哈希后不会均匀分布）

**Tips:**

Java语言在刷题过程中，可以认为 哈希表每时每刻 增删改查的代价都是$O(1)$的

(C++不行，它没有离线技术，但是在 N较小时候也可以认为是 $O(1)$)

原因：

1. 工程上使用时 N 不会特别大，且每加入一条数据的扩容平均代价：$log^N$，但是$log^N$的系数 C 非常的小，也就使得代价逼近 $O(1)$
2. 哈希表有离线技术（在使用 JVM的语言中：如 Java中），扩容操作不需要用户等待：
   - 扩容是在后台进行的（离线时间）
   - 用户在扩容没有完成之前依然使用的是原来的哈希表（在线时间）

#### 哈希表应用

[380. O(1) 时间插入、删除和获取随机元素](https://leetcode-cn.com/problems/insert-delete-getrandom-o1/)

朴素 HashMap 方法

```java
class RandomizedSet {
    HashMap<Integer, Integer> map1;
    HashMap<Integer, Integer> map2;
    int size;

    public RandomizedSet() {
        map1 = new HashMap<>();
        map2 = new HashMap<>();
        size = 0;
    }

    public boolean insert(int val) {
        if (!map1.containsKey(val)) {
            map1.put(val, size);
            map2.put(size, val);
            size++;
            return true;
        }
        return false;
    }

    public boolean remove(int val) {
        if (!map1.containsKey(val)) {
            return false;
        }
        int idxVal = map1.get(val);
        int idxLast = size - 1;
        int lastVal = map2.get(idxLast);// 获取最后一个元素
        map1.put(lastVal, idxVal);
        map2.put(idxVal, lastVal);
        map1.remove(val);
        map2.remove(idxLast);
        size--;
        return true;
    }

    public int getRandom() {
        return map2.get(new Random().nextInt(size));
    }
}
```

优化后的 HashMap 方法

```java
class RandomizedSet {
    HashMap<Integer, Integer> map;
    List<Integer> list;
    Random rand;
    int size;

    public RandomizedSet() {
        map = new HashMap<>();
        list = new ArrayList<>();
        rand = new Random();
        size = 0;
    }

    public boolean insert(int val) {
        if (!map.containsKey(val)) {
            map.put(val, size);
            list.add(val);
            size++;
            return true;
        }
        return false;
    }

    public boolean remove(int val) {
        if (!map.containsKey(val)) {
            return false;
        }
        int idxVal = map.get(val);
        int lastVal = list.get(--size);
        map.put(lastVal, idxVal);
        list.set(idxVal, lastVal);
        map.remove(val);
        list.remove(size);
        return true;
    }

    public int getRandom() {
        return list.get(rand.nextInt(size));
    }
}
```

由于数据量有限，也可以用数组

```java
class RandomizedSet {
    HashMap<Integer, Integer> map;
    int[] list;
    Random rand;
    int size;

    public RandomizedSet() {
        map = new HashMap<>();
        list = new int[10000];
        rand = new Random();
        size = 0;
    }

    public boolean insert(int val) {
        if (!map.containsKey(val)) {
            map.put(val, size);
            list[size++] = val;
            return true;
        }
        return false;
    }

    public boolean remove(int val) {
        if (!map.containsKey(val)) {
            return false;
        }
        int idxVal = map.get(val);
        int idxLast = --size;
        int lastVal = list[idxLast];
        map.put(lastVal, idxVal);
        list[idxVal] = lastVal;
        map.remove(val);
        return true;
    }

    public int getRandom() {
        return list[rand.nextInt(size)];
    }
}
```

### 布隆过滤器

**布隆过滤器**（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的[二进制](https://zh.wikipedia.org/wiki/二进制)向量和一系列随机[映射函数](https://zh.wikipedia.org/wiki/映射)。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

#### 基本概念

如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。[链表](https://zh.wikipedia.org/wiki/链表)、[树](https://zh.wikipedia.org/wiki/树_(数据结构))、[散列表](https://zh.wikipedia.org/wiki/散列表)（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为${\displaystyle O(n),O(\log n),O(1)}$

#### 基本思想

布隆过滤器的原理是，当一个元素被加入集合时，通过K个[散列函数](https://zh.wikipedia.org/wiki/散列函数)将这个元素映射成一个位[数组](https://zh.wikipedia.org/wiki/数组)中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

#### 优点

相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数（${\displaystyle O(k)}$)。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。

布隆过滤器可以表示全集，其它任何数据结构都不能；

${\displaystyle k}$和${\displaystyle m}$相同，使用同一组散列函数的两个布隆过滤器的交并[[来源请求\]](https://zh.wikipedia.org/wiki/Wikipedia:列明来源)运算可以使用位操作进行。

#### 缺点

布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。

另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。

在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。

#### 应用

布隆过滤器广泛应用于网页黑名单系统、垃圾邮件过滤系统、爬虫网址判重系统、Hadoop等

- **网页爬虫对URL的去重**，避免爬去相同的URL地址

- **垃圾邮件过滤**，从数十亿个垃圾邮件列表中判断某邮箱是否是杀垃圾邮箱

- **解决数据库缓存击穿**，黑客攻击服务器时，会构建大量不存在于缓存中的key向服务器发起请求，在数据量足够大的时候，频繁的数据库查询会导致挂机。

- **Hadoop（分布式文件系统）**中布隆过滤器的应用：

  - 查询某一个数据在哪个文件里：

    每一个分布式文件都有一个布隆过滤器，想知道 key在哪个文件里，就用key去查每个布隆过滤器，然后在布隆过滤器查询出来的有限几个文件中遍历（因为布隆过滤器有一定失误率），就可以知道这个key属于哪个文件

大样本量的黑名单系统：

- 黑名单系统，查询url是否属于黑名单：
  - 搜索引擎根据 url 屏蔽敏感内容
  - 爬虫 url 去重

好处：省内存空间

坏处：一定存在失误率

- 但是这个失误率可以通过人为设计压低，比如压低到10w分之一以下，w分之一以下 
- 这里的失误率指的是对不属于黑名单系统的url 误判为属于黑名单系统，但是对于属于 黑名单系统的url **绝不会误判**为不属于黑名单系统（也就是宁可错杀三千，绝不放过一个）
- 这个失误率是可控的
- 不会产生严重的问题，因为它的失误不会误报已经在黑名单中的url

#### 降低失误率

失误率和 m(布隆过滤器存储空间) 有关，增大 m 可以降低失误率，提高准确率

#### 算法思路

假设有 N 个样本，单个样本 S 个字节，布隆过滤器大小 M个 bit 位， K个 hash函数 

**关键点：**

- 布隆过滤器大小 M 和 单样本大小 S 没有关系

  - 一个 单样本 URL 经过 K个 hash函数 计算得到 K个哈希值，K个哈希值%M 得到的位置去 相应的 bitMap 中描黑，只要保证哈希函数可以接受 URL的类型即可，和布隆过滤器大小无关

- 失误率和 M关系图

  ![image-20211129201323712](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111292013484.png)

- 在 N、M 固定情况下 失误率与 哈希函数个数关系图

  ![image-20211129205819505](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111292058619.png)

##### **布隆过滤器大小 M 的确定条件**

1. 样本量 N
2. 失误率

##### **M和K 求值公式：**

**未知参数：**

M: 布隆过滤器大小 （bit个数，对应空间：M/8  字节）

K: 哈希函数数量

**已知参数：**

N: 样本量大小

p: 失误率

公式：
$$
M = - \frac{N*ln^p}{(ln^2)^2}  （结果向上取整）
$$

$$
K = ln^2 * \frac mn = 0.7 * \frac mn   （结果向上取整）
$$

实际失误率 p (因为 M和K都向上取整了，所以 p 有一个实际失误率，它比原来的失误率更低)
$$
p = (1- e^{- \frac {nk}m})^k
$$

##### **如何设计 K 个哈希函数**

需要两个种子哈希函数 a 和 b，那么 K 个哈希函数可以表示为：

$a + K * b$ , K的取值是 1 到 K

```
第一个哈希函数：a + 1*b
第二个哈希函数：a + 2*b
第三个哈希函数：a + 3*b
第四个哈希函数：a + 4*b
```

这些哈希函数几乎独立

#### 算法题目

如果一个黑名单网站包含100亿个黑名单网页，每个网页最多占64B，设计一个系统，判断当前的URL是否在这个黑名单当中，要求额外空间不超过30GB，允许误差率为万分之一。

解题思路：布隆过滤器

#### **面试场景**

如果面试官允许有失误率，那么这道题百分之百是用布隆过滤器去做

## 一致性哈希

### 经典服务器结构

![经典服务器结构](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111292252526.png)

1. 前端服务器将请求转发给可用的逻辑服务器
2. 逻辑服务器处理数据，将要新增（查询）的数据交给数据服务器处理
3. 依次返回给用户响应

分布式数据服务器组织方式：

- 经典方式：哈希函数

  - 前端服务器和逻辑服务器每一台都是等价的
  - 逻辑服务器计算出 key "mie" 的哈希函数值比如为 5，%3 之后计算结果为 2,那么就把 数据 data1 存入m2服务器上

- 根据哈希函数的性质，每台数据服务器所存有的数据量几乎是等量的，负载均衡

  - **负载均衡：**

    - （**hotkey问题**）在实际业务中： 有 高频、中频、低频，三种频率的key，**在key的种类足够多的情况下**

      高频 key		a 个

      中频 key		b 个

      低频 key		c 个

      假设有三台数据服务器，那么 高中低频key在每台服务器上数量差不多都是 1/3,，前提是a、b、c的数量都足够多，这是哈希函数的离散性决定的

      ![经典服务器结构](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111292311173.png) 

### 一致性哈希

一致性哈希可以把数据迁移的代价降到最低，达到负载均衡，并且可以管理负载

#### 经典服务器存在的问题

当**数据服务器**机器增减时，数据迁移代价特别大

#### 一致性哈希原理

##### 服务器分配

以MD5散列函数为例，MD5的返回值范围是 $0 到 2^{64} -1$,把这些值顺时针均分到一个环上

数据服务器（m1,m2,m3）组成集群，可以根据每台服务器的唯一标识（比如ip地址、mac地址等其中的一个做机器的唯一标识），进行 hash 得到一个 哈希值，然后把机器放到该位置上，这些服务器机器恰好把圆均分，故数据的存放也是均匀的，具有负载均衡的效果

##### 数据存放

假设有一个数据 data1，进行 hash后得到它的哈希值，接着按顺时针方向找到距离它最近的第一台机器，让这台机器来存放数据，如果找不到那就存放给第一台机器m0（因为这些机器组成了一个环）

##### 增加机器

新增机器 m4，根据它的唯一标识计算出一个哈希值，将它放到环上哈希值对应的位置

**增加机器后的数据迁移**

将原本属于 m1的数据迁移给m4，完成数据迁移

![image-20211130091651677](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111300916870.png)

##### 减少机器后的数据迁移

同理，将原本属于这台机器的数据给到顺时针距离它最近的机器上，完成数据迁移



##### 在机器数量较少时如何保证均分这个环,如何保证负载均衡

问题一：根据哈希函数的离散性，无法保证 m1,m2,m3 这三台机器恰好把环三等分

问题二：即便人为控制负载均衡（把环等分），后续新增机器、减少机器，如何保证负载均衡，如何把环等分

![image-20211130093713429](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111300937121.png)

**解决方案：**虚拟节点技术

为m1,m2,m3 各分配1000个字符串，放到路由表中

m1:a1,a2,a3,a4,a5……

m2:b1,b2,b3,b4,b5……

m3:c1,c2,c3,c4,c5……

即m1,m2,m3各有1000个虚拟节点，把这些虚拟节点进行 hash 得到一个 哈希值，然后把虚拟节点放到该位置上，这些虚拟节点就会恰好把圆均分

每一个虚拟节点存储的数据实际归属在物理机器m1,m2,m3上，由于哈希函数的离散型，这些虚拟节点均匀的分布在环上，物理机器m1,m2,m3也就均匀的各分配到了 1/3 的数据

所以利用虚拟节点技术，即便机器很少，也可以做到负载均衡，原因：是利用虚拟节点的比例在“抢环”；

**新增机器m4**：给m4也分配1000个虚拟节点，到环上，然后这1000个虚拟节点再向它附近的虚拟节点拿到它该拿的数据，底层就是m1,m2,m3 纷纷给m4数据，重新分完后每个机器各占 1/4，因为哈希函数保证了离散型。永远是**通过比例的方式给每一台机器负载均衡**。

减少机器原理相同，相当于m4把自己的数据非常均匀的给回了m1,m2,m3 ，**通过比例的方式给每一台机器分配数据，非常均衡**，详细过程不再赘述。



##### 负载分配

通过比例的方式，不仅可以做到负载均衡，还可以做到管理负载，为不同性能的机器分配合适数量的虚拟节点，做到了不同性能的机器的负载管理。

![image-20211130102216138](https://raw.githubusercontent.com/miemiehoho/blog/master/picture/2021/11/202111301022540.png)

##### 虚拟节点设计

按照自己想要的任何规则为每台机器分配就行，因为哈希函数的离散性会把有规律的输入变成无规律的离散

